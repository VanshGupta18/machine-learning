{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ZfGYr5SM2nTUH6L8Okxry2LQ8oeFngOb",
      "authorship_tag": "ABX9TyPMwvg66Lnma4l+vvYyEatp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VanshGupta18/machine-learning/blob/main/ml_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ASSIGNMENT_3**"
      ],
      "metadata": {
        "id": "MVEc-2r63X44"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.K-Fold Cross Validation for Multiple Linear Regression (Least Square Error Fit)\n",
        "Download the dataset regarding USA House Price Prediction from the following link:\n",
        "https://drive.google.com/file/d/1O_NwpJT-8xGfU_-3llUl2sgPu0xllOrX/view?usp=sharing\n",
        "Load the dataset and Implement 5- fold cross validation for multiple linear regression\n",
        "(using least square error fit).\n",
        "Steps:\n",
        "\n",
        "a) Divide the dataset into input features (all columns except price) and output variable\n",
        "(price)\n",
        "\n",
        "b) Scale the values of input features.\n",
        "\n",
        "c) Divide input and output features into five folds.\n",
        "\n",
        "d) Run five iterations, in each iteration consider one-fold as test set and remaining\n",
        "four sets as training set. Find the beta (ð›½) matrix, predicted values, and R2_score\n",
        "for each iteration using least square error fit.\n",
        "\n",
        "e) Use the best value of (ð›½) matrix (for which R2_score is maximum), to train the\n",
        "regressor for 70% of data and test the performance for remaining 30% data."
      ],
      "metadata": {
        "id": "W634lEoRz4mM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Function to calculate beta using the least square error fit method\n",
        "def least_square_beta(X, y):\n",
        "    X = np.insert(X, 0, 1, axis=1) # Add a column of ones for the intercept\n",
        "    beta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
        "    return beta\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/USA_Housing.csv')\n",
        "\n",
        "# a) Divide the dataset into features (X) and target (y)\n",
        "X = df.drop('Price', axis=1).values\n",
        "y = df['Price'].values\n",
        "\n",
        "# b) Scale the values of input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# c) Divide input and output features into five folds\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# d) Run five iterations\n",
        "r2_scores = []\n",
        "betas = []\n",
        "for train_index, test_index in kf.split(X_scaled):\n",
        "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Calculate beta matrix\n",
        "    beta = least_square_beta(X_train, y_train)\n",
        "    betas.append(beta)\n",
        "\n",
        "    # Predict values and calculate R2_score\n",
        "    y_pred = np.insert(X_test, 0, 1, axis=1) @ beta\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    print(f\"R2 Score: {r2}\")\n",
        "\n",
        "# Find the best beta (for which R2_score is maximum)\n",
        "best_beta = betas[np.argmax(r2_scores)]\n",
        "print(f\"\\nBest Beta: {best_beta}\")\n",
        "\n",
        "# e) Train the regressor on 70% of data with the best beta and test on 30%\n",
        "X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "y_pred_final = np.insert(X_test_final, 0, 1, axis=1) @ best_beta\n",
        "final_r2 = r2_score(y_test_final, y_pred_final)\n",
        "print(f\"Final R2 Score on 30% test data with best beta: {final_r2}\")"
      ],
      "metadata": {
        "id": "Rx7baNyR2xqr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d24fddc9-f983-4784-d75d-e3e88fda56f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 Score: 0.9179971706985147\n",
            "R2 Score: 0.9145677884802818\n",
            "R2 Score: 0.9116116385364478\n",
            "R2 Score: 0.9193091764960816\n",
            "R2 Score: 0.9243869413350316\n",
            "\n",
            "Best Beta: [1.23161736e+06 2.30225051e+05 1.63956839e+05 1.21115120e+05\n",
            " 7.83467170e+02 1.50662447e+05]\n",
            "Final R2 Score on 30% test data with best beta: 0.9147458156636434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Concept of Validation set for Multiple Linear Regression (Gradient Descent\n",
        "Optimization)\n",
        "Consider the same dataset of Q1, rather than dividing the dataset into five folds, divide the\n",
        "dataset into training set (56%), validation set (14%), and test set (30%).\n",
        "Consider four different values of learning rate i.e. {0.001,0.01,0.1,1}. Compute the values of\n",
        "regression coefficients for each value of learning rate after 1000 iterations.\n",
        "For each set of regression coefficients, compute R2_score for validation and test set and find\n",
        "the best value of regression coefficients. \u0000"
      ],
      "metadata": {
        "id": "5ap87E1n4p0D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGKVyCsFzwro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc6a0e39-3d8a-4c95-8ff3-c9502c05dedb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with learning rate: 0.001\n",
            "R2 Score on Validation Set: 0.6467117844424869\n",
            "R2 Score on Test Set: 0.6531360260800088\n",
            "\n",
            "Training with learning rate: 0.01\n",
            "R2 Score on Validation Set: 0.9202206893493433\n",
            "R2 Score on Test Set: 0.9133419052066929\n",
            "\n",
            "Training with learning rate: 0.1\n",
            "R2 Score on Validation Set: 0.9202207766800662\n",
            "R2 Score on Test Set: 0.9133419747998835\n",
            "\n",
            "Training with learning rate: 1\n",
            "R2 Score on Validation Set: -inf\n",
            "R2 Score on Test Set: -inf\n",
            "\n",
            "Best Regression Coefficients based on Validation Set R2 Score:\n",
            "Learning Rate: 0.1\n",
            "Coefficients (Beta): [1232180.27200919  230645.88389435  165328.94019375  120045.00851908\n",
            "    2945.02108903  151375.22971285]\n",
            "R2 Score on Validation Set: 0.9202207766800662\n",
            "R2 Score on Test Set: 0.9133419747998835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_regression.py:1275: RuntimeWarning: overflow encountered in square\n",
            "  numerator = xp.sum(weight * (y_true - y_pred) ** 2, axis=0)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_regression.py:1275: RuntimeWarning: overflow encountered in square\n",
            "  numerator = xp.sum(weight * (y_true - y_pred) ** 2, axis=0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Function for Gradient Descent\n",
        "def gradient_descent(X, y, learning_rate, iterations):\n",
        "    m, n = X.shape\n",
        "    X_b = np.insert(X, 0, 1, axis=1)  # Add intercept term\n",
        "    beta = np.zeros(n + 1)\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        gradients = (2/m) * X_b.T @ (X_b @ beta - y)\n",
        "        beta -= learning_rate * gradients\n",
        "\n",
        "    return beta\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/USA_Housing.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('Price', axis=1).values\n",
        "y = df['Price'].values\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Divide the dataset into training (56%), validation (14%), and test (30%) sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.44, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.68, random_state=42) # 14/44 ~= 32% (approx)\n",
        "\n",
        "learning_rates = [0.001, 0.01, 0.1, 1]\n",
        "results = []\n",
        "\n",
        "for lr in learning_rates:\n",
        "    print(f\"\\nTraining with learning rate: {lr}\")\n",
        "    beta = gradient_descent(X_train, y_train, lr, 1000)\n",
        "\n",
        "    # Calculate R2_score for validation and test sets\n",
        "    X_val_b = np.insert(X_val, 0, 1, axis=1)\n",
        "    y_pred_val = X_val_b @ beta\n",
        "    r2_val = r2_score(y_val, y_pred_val)\n",
        "\n",
        "    X_test_b = np.insert(X_test, 0, 1, axis=1)\n",
        "    y_pred_test = X_test_b @ beta\n",
        "    r2_test = r2_score(y_test, y_pred_test)\n",
        "\n",
        "    results.append({'learning_rate': lr, 'beta': beta, 'R2_val': r2_val, 'R2_test': r2_test})\n",
        "    print(f\"R2 Score on Validation Set: {r2_val}\")\n",
        "    print(f\"R2 Score on Test Set: {r2_test}\")\n",
        "\n",
        "# Find the best regression coefficients\n",
        "best_result = max(results, key=lambda x: x['R2_val'])\n",
        "print(\"\\nBest Regression Coefficients based on Validation Set R2 Score:\")\n",
        "print(f\"Learning Rate: {best_result['learning_rate']}\")\n",
        "print(f\"Coefficients (Beta): {best_result['beta']}\")\n",
        "print(f\"R2 Score on Validation Set: {best_result['R2_val']}\")\n",
        "print(f\"R2 Score on Test Set: {best_result['R2_test']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-processing and Multiple Linear Regression\n",
        "Download the dataset regarding Car Price Prediction from the following link:\n",
        "https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\n",
        "1. Load the dataset with following column names [\"symboling\", \"normalized_losses\",\n",
        "\"make\", \"fuel_type\", \"aspiration\",\"num_doors\", \"body_style\", \"drive_wheels\",\n",
        "\"engine_location\", \"wheel_base\", \"length\", \"width\", \"height\", \"curb_weight\",\n",
        "\"engine_type\", \"num_cylinders\", \"engine_size\", \"fuel_system\", \"bore\", \"stroke\",\n",
        "\"compression_ratio\", \"horsepower\", \"peak_rpm\", \"city_mpg\", \"highway_mpg\", \"price\"]\n",
        "and replace all ? values with NaN\n",
        "2. Replace all NaN values with central tendency imputation. Drop the rows with NaN\n",
        "values in price column\n",
        "3. There are 10 columns in the dataset with non-numeric values. Convert these values to\n",
        "numeric values using following scheme:\n",
        "(i) For â€œnum_doorsâ€ and â€œnum_cylindersâ€: convert words (number names) to figures\n",
        "for e.g., two to 2\n",
        "(ii) For \"body_style\", \"drive_wheels\": use dummy encoding scheme\n",
        "(iii) For â€œmakeâ€, â€œaspirationâ€, â€œengine_locationâ€,fuel_type: use label encoding\n",
        "scheme\n",
        "(iv) For fuel_system: replace values containing string pfi to 1 else all values to 0.\n",
        "(v) For engine_type: replace values containing string ohc to 1 else all values to 0.\n",
        "4. Divide the dataset into input features (all columns except price) and output variable\n",
        "(price). Scale all input features.\n",
        "5. Train a linear regressor on 70% of data (using inbuilt linear regression function of\n",
        "Python) and test its performance on remaining 30% of data.\n",
        "6. Reduce the dimensionality of the feature set using inbuilt PCA decomposition and then\n",
        "again train a linear regressor on 70% of reduced data (using inbuilt linear regression\n",
        "function of Python). Does it lead to any performance improvement on test set?"
      ],
      "metadata": {
        "id": "PQNQn_t65RKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# 1. Load the dataset with specified column names and replace '?' with NaN\n",
        "column_names = [\"symboling\", \"normalized_losses\", \"make\", \"fuel_type\", \"aspiration\",\n",
        "                \"num_doors\", \"body_style\", \"drive_wheels\", \"engine_location\",\n",
        "                \"wheel_base\", \"length\", \"width\", \"height\", \"curb_weight\",\n",
        "                \"engine_type\", \"num_cylinders\", \"engine_size\", \"fuel_system\",\n",
        "                \"bore\", \"stroke\", \"compression_ratio\", \"horsepower\", \"peak_rpm\",\n",
        "                \"city_mpg\", \"highway_mpg\", \"price\"]\n",
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data',\n",
        "                 names=column_names, na_values='?')\n",
        "\n",
        "# 2. Imputation and dropping rows\n",
        "for col in ['normalized_losses', 'horsepower', 'peak_rpm', 'price', 'bore', 'stroke']:\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    df[col] = imputer.fit_transform(df[[col]])\n",
        "df.dropna(subset=['price'], inplace=True) # Drop rows with NaN in price column\n",
        "\n",
        "# 3. Non-numeric to numeric conversion\n",
        "# (i) 'num_doors' and 'num_cylinders'\n",
        "door_map = {'two': 2, 'four': 4}\n",
        "df['num_doors'] = df['num_doors'].map(door_map).fillna(4)\n",
        "cylinder_map = {'two': 2, 'three': 3, 'four': 4, 'five': 5, 'six': 6, 'eight': 8, 'twelve': 12}\n",
        "df['num_cylinders'] = df['num_cylinders'].map(cylinder_map)\n",
        "\n",
        "# (ii) Dummy encoding for 'body_style' and 'drive_wheels'\n",
        "df = pd.get_dummies(df, columns=['body_style', 'drive_wheels'], drop_first=True)\n",
        "\n",
        "# (iii) Label encoding\n",
        "label_encoder = LabelEncoder()\n",
        "for col in ['make', 'aspiration', 'engine_location', 'fuel_type']:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        "\n",
        "# (iv) 'fuel_system' encoding\n",
        "df['fuel_system'] = df['fuel_system'].apply(lambda x: 1 if 'pfi' in str(x) else 0)\n",
        "\n",
        "# (v) 'engine_type' encoding\n",
        "df['engine_type'] = df['engine_type'].apply(lambda x: 1 if 'ohc' in str(x) else 0)\n",
        "\n",
        "# 4. Divide and scale\n",
        "X = df.drop('price', axis=1)\n",
        "y = df['price']\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# 5. Train and test without PCA\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "linear_reg = LinearRegression()\n",
        "linear_reg.fit(X_train, y_train)\n",
        "y_pred = linear_reg.predict(X_test)\n",
        "r2_before_pca = r2_score(y_test, y_pred)\n",
        "print(f\"R2 Score before PCA: {r2_before_pca}\")\n",
        "\n",
        "# 6. Reduce dimensionality with PCA and retrain\n",
        "pca = PCA(n_components=0.95) # Retain 95% of variance\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n",
        "\n",
        "linear_reg_pca = LinearRegression()\n",
        "linear_reg_pca.fit(X_train_pca, y_train_pca)\n",
        "y_pred_pca = linear_reg_pca.predict(X_test_pca)\n",
        "r2_after_pca = r2_score(y_test_pca, y_pred_pca)\n",
        "print(f\"R2 Score after PCA: {r2_after_pca}\")\n",
        "\n",
        "# Comparison\n",
        "if r2_after_pca > r2_before_pca:\n",
        "    print(\"\\nPerformance improved after PCA.\")\n",
        "elif r2_after_pca < r2_before_pca:\n",
        "    print(\"\\nPerformance decreased after PCA.\")\n",
        "else:\n",
        "    print(\"\\nPerformance remained the same after PCA.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlo6QduM5LF2",
        "outputId": "a9fe3209-0499-4023-f820-dd541df81ec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 Score before PCA: 0.804442243576259\n",
            "R2 Score after PCA: 0.7500675882701553\n",
            "\n",
            "Performance decreased after PCA.\n"
          ]
        }
      ]
    }
  ]
}